import os
import json
import numpy as np
import librosa
import soundfile as sf
from scipy.io import wavfile
import requests
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from tempfile import NamedTemporaryFile
import traceback
from pydub import AudioSegment

# =============================================================
# CONFIG
# =============================================================

ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY", "YOUR_ELEVENLABS_API_KEY")
VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID", "YOUR_VOICE_ID")
ELEVENLABS_BASE_URL = "https://api.elevenlabs.io/v1"

app = Flask(__name__)
CORS(app)

# =============================================================
# STEP 1: EXTRACT LYRICS FROM AUDIO
# =============================================================

def extract_lyrics_from_audio(audio_path: str) -> str:
    """
    Extract lyrics/speech from audio using speech recognition.
    This is a stub - you can integrate with Whisper or other STT.
    """
    print("[LYRICS] Extracting lyrics from audio...")
    # TODO: Integrate OpenAI Whisper or similar
    # For now, return placeholder
    try:
        import speech_recognition as sr
        recognizer = sr.Recognizer()
        with sr.AudioFile(audio_path) as source:
            audio = recognizer.record(source)
            text = recognizer.recognize_google(audio)
            print(f"[LYRICS] Extracted: {text}")
            return text
    except Exception as e:
        print(f"[WARN] Speech recognition failed: {str(e)}")
        print("[WARN] Using placeholder text")
        return "This is a perfect performance with beautiful vocals"


# =============================================================
# STEP 2: READ TEXT FILE
# =============================================================

def read_text_file(file_path: str) -> str:
    """
    Read lyrics from a text file (.txt, .srt, etc.)
    """
    print(f"[TEXT] Reading text file: {file_path}")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            text = f.read().strip()
            print(f"[TEXT] Read {len(text)} characters")
            return text
    except Exception as e:
        print(f"[ERROR] Failed to read text file: {str(e)}")
        raise


# =============================================================
# STEP 3: SEPARATE VOCALS & BACKGROUND MUSIC
# =============================================================

def separate_vocals_and_music(audio_path: str):
    """
    Separate vocals from background music using librosa.
    Returns: (vocals_audio, background_audio, sr)
    """
    print("[SEPARATION] Separating vocals and background music...")
    try:
        y, sr = librosa.load(audio_path, sr=None, mono=False)
        
        # If stereo, convert to mono for processing
        if len(y.shape) > 1:
            y = np.mean(y, axis=0)
        
        # Use HPSS (Harmonic/Percussive Source Separation)
        # Harmonic = sustained notes (vocals, sustained instruments)
        # Percussive = drums, rhythm
        H, P = librosa.decompose.hpss(librosa.stft(y))
        harmonic = librosa.istft(H)
        percussive = librosa.istft(P)
        
        print(f"[SEPARATION] Separated into harmonic (vocals) and percussive (background)")
        
        # Background = percussive + some harmonic blend
        background = 0.7 * percussive + 0.3 * harmonic
        
        return harmonic, background, sr
        
    except Exception as e:
        print(f"[WARN] Separation failed: {str(e)}")
        print("[WARN] Using full audio as background")
        y, sr = librosa.load(audio_path, sr=None, mono=True)
        return None, y, sr


# =============================================================
# STEP 4: EXTRACT MELODY/TIMING FROM VOCALS
# =============================================================

def extract_melody_timing(audio_path: str, hop_length=512):
    """
    Extract pitch contour and timing from audio.
    Returns melody info needed to sync with lyrics.
    """
    print("[MELODY] Extracting melody and timing...")
    try:
        y, sr = librosa.load(audio_path, sr=None, mono=True)
        
        # Extract pitch
        f0, voiced_flag, voiced_prob = librosa.pyin(
            y,
            fmin=librosa.note_to_hz('C2'),
            fmax=librosa.note_to_hz('C7'),
            sr=sr,
            hop_length=hop_length,
            trough_threshold=0.1
        )
        
        # Get timing
        times = librosa.frames_to_time(np.arange(len(f0)), sr=sr, hop_length=hop_length)
        
        melody_info = {
            "sr": int(sr),
            "duration": float(len(y) / sr),
            "times": times.tolist(),
            "f0": np.nan_to_num(f0).tolist(),
            "voiced_flag": voiced_flag.astype(int).tolist(),
            "hop_length": hop_length
        }
        
        print(f"[MELODY] Duration: {melody_info['duration']:.2f}s")
        print(f"[MELODY] Pitch range: {np.nanmin(f0):.1f} - {np.nanmax(f0):.1f} Hz")
        
        return melody_info
        
    except Exception as e:
        print(f"[ERROR] Melody extraction failed: {str(e)}")
        raise


# =============================================================
# STEP 5: GENERATE SINGING WITH ELEVENLABS
# =============================================================

def generate_singing_audio(text: str, voice_id: str, duration: float, 
                          stability=0.5, similarity=0.75) -> bytes:
    """
    Use ElevenLabs to generate singing audio.
    Will be the same duration as the original backing track.
    """
    print(f"[ELEVENLABS] Generating singing voice for {duration:.2f}s")
    print(f"[ELEVENLABS] Text: '{text}'")
    
    url = f"{ELEVENLABS_BASE_URL}/text-to-speech/{voice_id}"
    
    headers = {
        "xi-api-key": ELEVENLABS_API_KEY,
        "Content-Type": "application/json",
        "Accept": "audio/mpeg"
    }
    
    payload = {
        "text": text,
        "model_id": "eleven_multilingual_v2",
        "voice_settings": {
            "stability": float(stability),
            "similarity_boost": float(similarity)
        }
    }
    
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        
        if response.status_code != 200:
            print(f"[ERROR] ElevenLabs error: {response.status_code}")
            print(f"[ERROR] Response: {response.text}")
            raise RuntimeError(f"ElevenLabs API error: {response.status_code}")
        
        print("[ELEVENLABS] Successfully generated singing audio")
        return response.content
        
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] Network error: {str(e)}")
        raise


# =============================================================
# STEP 6: MIX VOCAL WITH BACKGROUND MUSIC
# =============================================================

def mix_vocal_with_background(vocal_path: str, background_path: str, 
                             vocal_volume=1.0, background_volume=0.7) -> bytes:
    """
    Mix the generated vocal with background music.
    Returns MP3 bytes.
    """
    print("[MIX] Mixing vocal with background music...")
    
    try:
        # Load vocal (MP3 from ElevenLabs)
        vocal_audio = AudioSegment.from_mp3(vocal_path)
        
        # Load background (WAV)
        background_audio = AudioSegment.from_wav(background_path)
        
        print(f"[MIX] Vocal duration: {len(vocal_audio)}ms")
        print(f"[MIX] Background duration: {len(background_audio)}ms")
        
        # Make them the same length
        target_length = len(background_audio)
        
        if len(vocal_audio) < target_length:
            # Pad vocal with silence
            silence = AudioSegment.silent(duration=target_length - len(vocal_audio))
            vocal_audio = vocal_audio + silence
            print(f"[MIX] Padded vocal with silence")
        elif len(vocal_audio) > target_length:
            # Trim vocal
            vocal_audio = vocal_audio[:target_length]
            print(f"[MIX] Trimmed vocal to match background")
        
        # Adjust volumes
        vocal_audio = vocal_audio + (20 * np.log10(vocal_volume))  # dB adjustment
        background_audio = background_audio + (20 * np.log10(background_volume))
        
        # Mix
        mixed = vocal_audio.overlay(background_audio)
        
        print(f"[MIX] Final duration: {len(mixed)}ms")
        
        # Export as MP3
        mp3_bytes = mixed.export(format="mp3").read()
        print("[MIX] Mixed audio exported as MP3")
        
        return mp3_bytes
        
    except Exception as e:
        print(f"[ERROR] Mixing failed: {str(e)}")
        raise


# =============================================================
# MAIN ENDPOINT: /create-perfect-performance
# =============================================================

@app.route("/create-perfect-performance", methods=["POST"])
def create_perfect_performance():
    """
    Main endpoint: Create perfect singing with backing track.
    
    INPUTS (choose one option):
      Option A:
        - vocal_audio: file with singing + music
        - backing_track: (optional) pure music file to use instead
        - lyrics_file: (optional) text file with lyrics
      
      Option B:
        - backing_track: pure music file
        - lyrics_file: text file with lyrics
    
    OUTPUTS:
      - MP3 file with perfect AI singing + original backing music
    """
    
    try:
        print("\n" + "="*60)
        print("ENDPOINT: /create-perfect-performance")
        print("="*60)
        
        # Validate inputs
        if "backing_track" not in request.files:
            return jsonify({"error": "backing_track file required"}), 400
        
        backing_file = request.files["backing_track"]
        vocal_file = request.files.get("vocal_audio", None)
        lyrics_file = request.files.get("lyrics_file", None)
        
        # Get voice settings
        stability = float(request.form.get("stability", 0.5))
        similarity = float(request.form.get("similarity", 0.75))
        vocal_volume = float(request.form.get("vocal_volume", 1.0))
        background_volume = float(request.form.get("background_volume", 0.7))
        
        print(f"[INPUT] Backing track: {backing_file.filename}")
        print(f"[INPUT] Vocal audio: {vocal_file.filename if vocal_file else 'None'}")
        print(f"[INPUT] Lyrics file: {lyrics_file.filename if lyrics_file else 'None'}")
        print(f"[INPUT] Settings: stability={stability}, similarity={similarity}")
        
        # Save files temporarily
        with NamedTemporaryFile(delete=False, suffix=".wav") as f_backing:
            backing_file.save(f_backing.name)
            backing_path = f_backing.name
        
        vocal_path = None
        lyrics_text = None
        
        if vocal_file:
            with NamedTemporaryFile(delete=False, suffix=".wav") as f_vocal:
                vocal_file.save(f_vocal.name)
                vocal_path = f_vocal.name
        
        if lyrics_file:
            with NamedTemporaryFile(delete=False, suffix=".txt") as f_lyrics:
                lyrics_file.save(f_lyrics.name)
                lyrics_text = read_text_file(f_lyrics.name)
        
        # ===== PIPELINE =====
        
        # 1) Get lyrics (either from file or extract from vocal)
        if lyrics_text:
            print(f"[FLOW] Using provided lyrics")
        elif vocal_path:
            print(f"[FLOW] Extracting lyrics from vocal audio")
            lyrics_text = extract_lyrics_from_audio(vocal_path)
        else:
            return jsonify({"error": "Must provide either lyrics_file or vocal_audio"}), 400
        
        print(f"[FLOW] Lyrics: {lyrics_text[:100]}...")
        
        # 2) Get melody timing (from vocal audio if available)
        melody_info = None
        if vocal_path:
            melody_info = extract_melody_timing(vocal_path)
            duration = melody_info["duration"]
        else:
            # Use backing track duration
            y, sr = librosa.load(backing_path, sr=None, mono=True)
            duration = len(y) / sr
            print(f"[FLOW] Using backing track duration: {duration:.2f}s")
        
        # 3) Generate perfect singing with ElevenLabs
        print(f"[FLOW] Generating perfect singing voice...")
        vocal_mp3_bytes = generate_singing_audio(
            text=lyrics_text,
            voice_id=VOICE_ID,
            duration=duration,
            stability=stability,
            similarity=similarity
        )
        
        # Save vocal MP3 temporarily
        with NamedTemporaryFile(delete=False, suffix=".mp3") as f_vocal_mp3:
            f_vocal_mp3.write(vocal_mp3_bytes)
            vocal_mp3_path = f_vocal_mp3.name
        
        # 4) Convert backing track to WAV if needed
        print("[FLOW] Preparing backing track...")
        if backing_file.filename.lower().endswith('.mp3'):
            # Convert MP3 to WAV
            audio = AudioSegment.from_mp3(backing_path)
            with NamedTemporaryFile(delete=False, suffix=".wav") as f_wav:
                audio.export(f_wav.name, format="wav")
                backing_wav_path = f_wav.name
        else:
            backing_wav_path = backing_path
        
        # 5) Mix vocal with backing track
        print("[FLOW] Mixing perfect vocal with backing track...")
        final_mp3_bytes = mix_vocal_with_background(
            vocal_path=vocal_mp3_path,
            background_path=backing_wav_path,
            vocal_volume=vocal_volume,
            background_volume=background_volume
        )
        
        # 6) Save final output
        with NamedTemporaryFile(delete=False, suffix=".mp3") as f_output:
            f_output.write(final_mp3_bytes)
            output_path = f_output.name
        
        print("[SUCCESS] Perfect performance created!")
        print("="*60 + "\n")
        
        return send_file(
            output_path,
            mimetype="audio/mpeg",
            as_attachment=True,
            download_name="perfect_performance.mp3"
        )
        
    except Exception as e:
        print(f"[FATAL ERROR] {str(e)}")
        print(traceback.format_exc())
        return jsonify({"error": str(e), "details": traceback.format_exc()}), 500


# =============================================================
# DIAGNOSTICS
# =============================================================

@app.route("/", methods=["GET"])
def index():
    return jsonify({
        "status": "V-Perfection Perfect Performance Backend",
        "version": "3.0",
        "endpoint": "POST /create-perfect-performance"
    })


@app.route("/health", methods=["GET"])
def health():
    return jsonify({
        "status": "healthy",
        "elevenlabs_configured": ELEVENLABS_API_KEY != "YOUR_ELEVENLABS_API_KEY",
        "voice_id_configured": VOICE_ID != "YOUR_VOICE_ID"
    })


if __name__ == "__main__":
    print("\nðŸŽ¤ V-PERFECTION PERFECT PERFORMANCE BACKEND v3.0\n")
    print("Features:")
    print("  âœ“ Upload backing track + vocals (or just backing + lyrics file)")
    print("  âœ“ Extract lyrics from vocals (or use provided text)")
    print("  âœ“ Generate perfect singing with ElevenLabs")
    print("  âœ“ Mix vocal over backing track")
    print("  âœ“ Output professional MP3\n")
    print(f"API Key: {ELEVENLABS_API_KEY != 'YOUR_ELEVENLABS_API_KEY'}")
    print(f"Voice ID: {VOICE_ID != 'YOUR_VOICE_ID'}\n")
    app.run(host="0.0.0.0", port=5000, debug=True)